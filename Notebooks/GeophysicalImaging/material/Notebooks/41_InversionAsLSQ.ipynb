{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "toc": true
         },
         "source": [
            "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
            "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Inversion-as-Quadratic-Programming-Problem\" data-toc-modified-id=\"Inversion-as-Quadratic-Programming-Problem-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Inversion as Quadratic Programming Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#Formulation-of-the-Problem\" data-toc-modified-id=\"Formulation-of-the-Problem-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Formulation of the Problem</a></span></li><li><span><a href=\"#FEM-Forward-Model\" data-toc-modified-id=\"FEM-Forward-Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>FEM Forward Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#FEM-domain\" data-toc-modified-id=\"FEM-domain-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>FEM domain</a></span></li><li><span><a href=\"#Definition-of-indicator-functions\" data-toc-modified-id=\"Definition-of-indicator-functions-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Definition of indicator functions</a></span></li><li><span><a href=\"#Create-a-density-distribution\" data-toc-modified-id=\"Create-a-density-distribution-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Create a density distribution</a></span></li><li><span><a href=\"#Compute-the-gravity-field\" data-toc-modified-id=\"Compute-the-gravity-field-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Compute the gravity field</a></span></li><li><span><a href=\"#Grab-the-data-along-a-line\" data-toc-modified-id=\"Grab-the-data-along-a-line-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Grab the data along a line</a></span></li><li><span><a href=\"#Forward-model-in-a-compact-form\" data-toc-modified-id=\"Forward-model-in-a-compact-form-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>Forward model in a compact form</a></span></li></ul></li><li><span><a href=\"#Critical-Point-Condition\" data-toc-modified-id=\"Critical-Point-Condition-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Critical Point Condition</a></span><ul class=\"toc-item\"><li><span><a href=\"#Jacobean-for-the-gravity-problem\" data-toc-modified-id=\"Jacobean-for-the-gravity-problem-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Jacobean for the gravity problem</a></span></li><li><span><a href=\"#The-linear-model-case\" data-toc-modified-id=\"The-linear-model-case-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>The linear model case</a></span></li></ul></li><li><span><a href=\"#Solution\" data-toc-modified-id=\"Solution-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Solution</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-Attempt\" data-toc-modified-id=\"First-Attempt-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>First Attempt</a></span></li><li><span><a href=\"#SVD\" data-toc-modified-id=\"SVD-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>SVD</a></span></li><li><span><a href=\"#Some-Analysis\" data-toc-modified-id=\"Some-Analysis-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Some Analysis</a></span></li></ul></li><li><span><a href=\"#Solution-Strategies\" data-toc-modified-id=\"Solution-Strategies-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Solution Strategies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mode-dropping\" data-toc-modified-id=\"Mode-dropping-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Mode dropping</a></span></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Filtering</a></span></li></ul></li><li><span><a href=\"#Regularization\" data-toc-modified-id=\"Regularization-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Regularization</a></span></li><li><span><a href=\"#L-curves\" data-toc-modified-id=\"L-curves-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>L-curves</a></span></li></ul></li></ul></div>"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "by Lutz Gross, The University of Queensland, Australia\n",
            "<a href=\"mailto:l.gross@uq.edu.au\">l.gross@uq.edu.au</a>\n",
            "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We will use this at one point in time "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "#%matplotlib notebook # commmend for interactive plots\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "mGal=100000\n",
            "G=6.67e-11  # m^3/kg/sec^2 gravity constant\n",
            "\n",
            "# this makes the random number generation reproducable: \n",
            "np.random.seed(seed=9)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Inversion as Quadratic Programming Problem\n",
            "## Formulation of the Problem\n",
            "\n",
            "**Problem:** How to fit geophysical properties to known observation?\n",
            "\n",
            "For instance: finding the density anomaly creating a given vertical gravity profile along a transect. \n",
            "\n",
            "In mathematical terms this task is state as an optimization problem: \n",
            "\n",
            "- given observations $d_i^{obs}$ for observation points $i$ with $i=0\\ldots,N_d-1$.\n",
            "- given a forward model $F_i(\\mathbf{m})$ providing a prediction $d_i$ for the observations given a realization $\\mathbf{m}$ of the unknown geophysical properties.\n",
            "\n",
            "**Task:** Find $\\mathbf{m}^*$ that minimizes the difference between $d_i = F_i(\\mathbf{m})$ and $d_i^{obs}$.\n",
            "\n",
            "Obviously this needs to be formalized more.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The most common form of measuring misfit is \n",
            "a quadratic form $\\Phi_d$ in the form \n",
            "\\begin{equation}\\label{eq:misfit}\n",
            "\\Phi_d(\\mathbf{m}) = \\frac{1}{2} \\sum_{i=0}^{N_d-1} w^{obs}_i \\cdot |F_i(\\mathbf{m})-d_i^{obs}|^2\n",
            "\\end{equation}\n",
            "where $w^{obs}_k$ are positive weighting factors allowing for adjustments of \n",
            "contributions of measurement to the misfit.\n",
            "\n",
            "When measurement errors $\\sigma_i$ are available one can set \n",
            "\\begin{equation}\\label{eq:misfit2}\n",
            "\\Phi_d(\\mathbf{m}) = \\frac{1}{2} \\sum_{i=0}^{N_d-1} \\frac{1}{\\sigma_i^2} \\cdot |F_i(\\mathbf{m})-d_i^{obs}|^2\n",
            "\\end{equation}\n",
            "So we choose in \\eqref{eq:misfit}:\n",
            "\\begin{equation}\\label{eq:misfit3}\n",
            " w^{obs}_i  = \\frac{1}{N_d} \\frac{1}{\\sigma_i^2}\n",
            "\\end{equation}\n",
            "For this setting\n",
            "- $\\Phi_d(\\mathbf{m})<1$ means that in average prediction $d_k$ are a better match of the data $d_k^{obs}$ than the average error This case is referred to as over fitting. \n",
            "- $\\Phi_d(\\mathbf{m})>1$ indicates that data prediction are worse than the error and more work should be done to improve the misfit. This case is referred to as under fitting.\n",
            "    \n",
            "    \n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The misfit is sometimes written in matrix form:\n",
            "\\begin{equation}\\label{eq:misfit4}\n",
            "\\Phi_d(\\mathbf{m}) = \\frac{1}{2} (\\mathbf{d}-\\mathbf{d}^{obs})^T \\mathbf{W}_d (\\mathbf{d}-\\mathbf{d}^{obs})\n",
            "\\end{equation}\n",
            "where the prediction and observation vectors are given as\n",
            "\\begin{align}\\label{eq:misfit4.1}\n",
            "\\mathbf{d} = & [d_0, \\ldots, d_{N_d-1}]^T   \\\\\n",
            "\\mathbf{d}^{obs} = &  [d^{ops}_0, \\ldots, d^{ops}_{N_d-1}]^T\n",
            "\\end{align}\n",
            "\n",
            "\n",
            "\n",
            "The data weighting matrix $\\mathbf{W}_d$ is an $N_d \\times N_d$, diagonal matrix it is given as \n",
            "\\begin{equation}\\label{eq:misfit4.2}\n",
            "\\mathbf{W}_d =\n",
            "\\begin{bmatrix}\n",
            "w^{obs}_0  & 0        &            & 0\\\\\n",
            "    0      &  w^{obs}_1&           & 0\\\\\n",
            "    \\vdots       &        & \\ddots &    \\vdots\\\\\n",
            "        0         &       &       & w^{obs}_{N_d-1}\n",
            "\\end{bmatrix}\n",
            "\\end{equation}\n",
            "\n",
            "\n",
            "*Notes*\n",
            "- Misfit $\\Phi_d$ \\eqref{eq:misfit4} in case of complex valued data (eg. for MT) transposed $T$ needs to \n",
            "be replaced by the Hermitian transpose $H$. \n",
            "- $\\mathbf{W}_d$ may have a more general form but is required to be \n",
            "    - symmetric: $\\mathbf{W}_d =  \\mathbf{W}_d^T$ and \n",
            "    - positive definite: $\\mathbf{d}^T \\mathbf{W}_d \\mathbf{d} > 0$ for any non-zero vector $\\mathbf{d}$ These properties guaranty that the misfit has non-negative real values. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Inversion problem is given as a minimization problem, namely to find the vector $\\mathbf{m}^{*}$ of $N_p$ components as solution of  \n",
            "\\begin{equation}\\label{eq:minimization}\n",
            "\\underset{\\mathbf{m}}{\\mbox{minimize}} \\; \\Phi_d(\\mathbf{m})\n",
            "\\end{equation}\n",
            "\n",
            "For a two unknwons $\\mathbf{m}=(m_0, m_1)$ the misfit function could like like this:\n",
            "\n",
            "<img src=\"./Data/Image_minima.png\" alt=\"MT domain\" width=\"500\"> \n",
            " from https://medium.com/analytics-vidhya/journey-of-gradient-descent-from-local-to-global-c851eba3d367\n",
            "\n",
            "In order to solve this problem we first need to have a mean to evaluate the forward problem(s) $d_i = F_i(\\mathbf{m})$ which will do using the finite element method."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## FEM Forward Model\n",
            "\n",
            "We are looking at the gravity anomaly case:\n",
            "    \n",
            "Lets assume the shape of the density anomaly is known but its density $m_0=\\rho_0$ is unknown.     \n",
            "\n",
            "To describe the geometry we use a so called in indicator function $\\chi$ which is takes the value \n",
            "one for locations with in the anomaly and zero outside, see Figure~\\ref{fig:indicator_function}. \n",
            "Formally this is expressed as \n",
            "\\begin{equation}\\label{eq:indicator}\n",
            "\\chi(\\mathbf{x}) = \\left\\{ \n",
            "\\begin{array}{cl}\n",
            "1 & \\mathbf{x} \\mbox{ locate inside the anomaly } \\\\\n",
            "0 & \\mbox{ otherwise }\n",
            "\\end{array}\n",
            "\\right.\n",
            "\\end{equation}\n",
            "<img src=\"./Data/IMAGE_Indicator_function.png\" alt=\"MT domain\" width=\"300\"> \n",
            "With this setting a density distribution $\\rho$ is space is defined as \n",
            "\\begin{equation}\\label{eq:prop0}\n",
            "\\rho = m_0 \\cdot \\chi\n",
            "\\end{equation}\n",
            "which then defines the right hand side of the PDE we need to solve. \n",
            "The property vector $\\mathbf{m}=[m_0]$ has one entry only that defines the density in the anomaly.\n",
            "\n",
            "\n",
            "This concept can be extended by using a set of $N_p$ anomalies each with constant density $m_k$. Then we \n",
            "set\n",
            "\\begin{equation}\\label{eq:prop1}\n",
            "\\rho = \\sum_{k=0}^{N_p-1} m_k \\chi_{k}\n",
            "\\end{equation}\n",
            "Typically one would choose the anomaly non over-lapping but this is not required.\n",
            "When the functions $\\chi_{k}$ are in fact indicator functions then this approach for $\\rho$\n",
            "also referred to as piecewise constant."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "A general anomaly can be approximated using patches in the form of square or rectangular patches in an $4 \\times 3$ array which is aligned with the FEM grid. Here we use eight patches  (with six observation points $N_d=6$) \n",
            "over a $29 \\times 18$ computational grid for solving the forward PDE. \n",
            "<img src=\"./Data/IMAGE_fitting_grid.png\" alt=\"MT domain\" width=\"400\"> \n",
            "Notice that grid lines are aligned with patch boundaries.\n",
            "\n",
            "The $N_p$-dimensional vector property $\\mathbf{m}$ \n",
            "\\begin{align}\\label{eq:prop3}\n",
            "\\mathbf{m} = & [m_0, \\ldots, m_{N_p-1}]^T \n",
            "\\end{align}\n",
            "is the unknown vector of the inversion. Each patch $k$ has a constant density $m_k$."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### FEM domain\n",
            "To set this up we first define a coarse grid in which we define patches and indicator functions $\\chi_k$: "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "NE0_coarse = 40  # number of coarse level cells in horizontal direction\n",
            "NE1_coarse = 20  # number of coarse level cells in vertical direction\n",
            "h_coarse = 2500. # grid spacing on coarse level [m]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Spatial extend of the domain based::"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'domain extend [m]: 100000.0 x  50000.0'"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "L0, L1= NE0_coarse*h_coarse, NE1_coarse*h_coarse\n",
            "f\"domain extend [m]: {L0} x  {L1}\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "With in this coarse level grid we define the patches in terms of patch grid dimension `PatchGrid_coarse` and\n",
            "origin `PatchOrigin_coarse` which is the lower left corner of the patch grid: "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "PatchGrid_coarse = (6,4)   # number of patches in x0 and x1 direction\n",
            "PatchOrigin_coarse = NE0_coarse//2 - PatchGrid_coarse[0]//2, NE1_coarse//2 - PatchGrid_coarse[1] #"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(17, 6)"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "PatchOrigin_coarse"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The line of observers along the  we place two cells above the top of the patch array: "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "ObserverHeight_coarse=PatchGrid_coarse[1]+PatchOrigin_coarse[1]+2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "12"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "ObserverHeight_coarse"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We introduce a refinement factor `Refine` so we can work with finer grid for the FEM solution. \n",
            "For instance a value `Refine=2` halfs each coarse level cell. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "Refine=4     # refinement factor \n",
            "DataStep=4   # use every `DataStep`-th element to grab data"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we have the compuational grid with $\\times \\mathtt{Refine}$ more elements in each direction. The \n",
            "element size is reduced accordingly to keep the extension of the domain as set by the coarse grid:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "NE0=NE0_coarse * Refine\n",
            "NE1=NE1_coarse * Refine\n",
            "h = h_coarse/Refine"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "As the refined domain the same extend as the original domain? "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {
            "run_control": {
               "marked": false
            }
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'domain extend [m]: 100000.0 x  50000.0'"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "f\"domain extend [m]: {NE0*h} x  {NE1*h}\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we can set up the `esys.finley` domain: "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "from esys.escript import *\n",
            "from esys.finley import Rectangle\n",
            "\n",
            "domain=Rectangle(n0=NE0, n1=NE1, l0=L0, l1=L1)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Definition of indicator functions\n",
            "\n",
            "Setting the indicator for patch $(k_0,k_1)$ we introduce four masks (with values values `0` and `1`) which are then combined the to define the region of the patch:\n",
            "\n",
            "- `m1` = has values `1` for elements above the bottom edge of the patch: $x_1 > (PatchOrigin\\_coarse[1]+k1)\\cdot h\\_coarse$\n",
            "- `m2` = has values `1` for elements below the top edge of the patch: $x_1 < (PatchOrigin\\_coarse[1]+k1+1)\\cdot h\\_coarse$\n",
            "- `m3` = has values `1` for elements to the right of left edge of the patch: $x_0 > (PatchOrigin\\_coarse[0]+k0)\\cdot h\\_coarse$\n",
            "- `m4` = has values `1` for elements to the left of right edge of the patch: $x_0 < (PatchOrigin\\_coarse[0]+k0+1)\\cdot h\\_coarse$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "chis=[]\n",
            "X=ReducedFunction(domain).getX()\n",
            "for k0 in range(PatchGrid_coarse[0]):  \n",
            "    for k1 in range(PatchGrid_coarse[1]):\n",
            "        m1=wherePositive(X[1]-(PatchOrigin_coarse[1]+k1)*h_coarse)\n",
            "        m2=whereNegative(X[1]-(PatchOrigin_coarse[1]+k1+1)*h_coarse)\n",
            "        m3=wherePositive(X[0]-(PatchOrigin_coarse[0]+k0)*h_coarse)\n",
            "        m4=whereNegative(X[0]-(PatchOrigin_coarse[0]+k0+1)*h_coarse)\n",
            "        chis.append(m1*m2*m3*m4)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Lets do little test and mark each patch `chi` by its index in the `chis` list :"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho=0\n",
            "for k,chi in enumerate(chis):\n",
            "    rho=rho+chi*(k+1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "ename": "RuntimeError",
               "evalue": "unidentifiable C++ exception",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rho_np\u001b[38;5;241m=\u001b[39m\u001b[43mconvertToNumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrho\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_np\u001b[38;5;241m=\u001b[39mconvertToNumpy(rho\u001b[38;5;241m.\u001b[39mgetX())\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
                  "File \u001b[0;32m~/PycharmProjects/esys-escript.github.io/escriptcore/py_src/util.py:291\u001b[0m, in \u001b[0;36mconvertToNumpy\u001b[0;34m(data)\u001b[0m\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: unidentifiable C++ exception"
               ]
            }
         ],
         "source": [
            "rho_np=convertToNumpy(rho)\n",
            "X_np=convertToNumpy(rho.getX())\n",
            "\n",
            "plt.figure()\n",
            "plt.tricontourf(X_np[0], X_np[1], rho_np[0], 25, cmap='tab20c')\n",
            "plt.xlabel('$x_0$ [m]')\n",
            "plt.ylabel('$x_1$ [m]')\n",
            "plt.colorbar()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "###  Create a density distribution\n",
            "\n",
            "Now we can create some test data $\\mathbf{d}^{obs}$ from an assumed density distribution from a propert vector $\\mathbf{m}_{true}$ using the patches:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m_true=np.zeros(PatchGrid_coarse)\n",
            "m_true[0,1]=1500\n",
            "m_true[4,3]=-1000"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's take a look at teh values over the patch. Notice the `.T` which is needed to swap the first and second dimension as `imshow` plot first dimension upward."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.clf()\n",
            "vmax=abs(m_true).max()\n",
            "plt.imshow(m_true.T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we can build a density distribution from `m_true` on the FEM grid:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho=0\n",
            "for k in range(m_true.size):\n",
            "    rho=rho+chis[k]*m_true.flat[k]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Always good to check:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho_np=convertToNumpy(rho)\n",
            "X_np=convertToNumpy(rho.getX())\n",
            "\n",
            "plt.figure()\n",
            "\n",
            "plt.tricontourf(X_np[0], X_np[1], rho_np[0], 15)\n",
            "plt.xlabel('$x_0$ [m]')\n",
            "plt.ylabel('$x_1$ [m]')\n",
            "plt.colorbar()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Compute the gravity field\n",
            "\n",
            "To compute the gravity field due to this density distribution we solve a PDE as discussed earlier:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from esys.escript.linearPDEs import LinearSinglePDE\n",
            "\n",
            "model=LinearSinglePDE(domain)\n",
            "x=domain.getX()\n",
            "model.setValue(A=np.eye(2), q=whereZero(x[1]-L1))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Set the right hand side of PDE and solve:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.setValue(Y=-4*np.pi*G*rho)\n",
            "u=model.getSolution()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "and the vertical gravity at element centers:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "gz=-grad(u, ReducedFunction(domain))[1]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Grab the data along a line\n",
            "\n",
            "We use a `Locator` to grab the vertical gravity. These are the horizontal positions of element centers:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "x0_line=np.linspace(h/2, L0-h/2, NE0)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Add vertical position at $x_1=ObserverHeight\\_coarse*h\\_coarse$ and create the `Locator`:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from esys.escript.pdetools import Locator\n",
            "line_locator=Locator(where=gz.getFunctionSpace(), x=[ (x0, ObserverHeight_coarse*h_coarse) for x0 in x0_line ] )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Get the vertical gravity alonh the line:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "gz_line=np.array(line_locator.getValue(gz))*mGal"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We take a subset of this as data (if `DataStep`>1). Notice the `copy` which is needed as the slicing creates a different view on `gz_line` only and we want to modify `d_obs` later."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "d_obs=gz_line[::DataStep].copy()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "To make this more interesting we add 10\\% random noise:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "d_obs*=(1+0.30*np.random.normal(scale=0.1, size=d_obs.shape))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "What is $N_d$?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "f\"number of data points N_d = {d_obs.size}.\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "plt.plot(x0_line, gz_line, label='true gz')\n",
            "plt.scatter(x0_line[::DataStep], d_obs, s=2, label='data')\n",
            "plt.xlabel('x [m]')\n",
            "plt.ylabel('gravity [mGal]')\n",
            "plt.legend()\n",
            "plt.title(\"gravity anomaly over transect @ height %g m\"%(line_locator.getX()[0][1]))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Check the misfit $\\Phi_d$ of data vector $\\mathbf{d}$ against the data assuming a constant error of $\\sigma_i=0.5 mGal$:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "d=gz_line[::DataStep].copy()\n",
            "phi_d=np.mean( (d-d_obs)**2/0.5**2)\n",
            "phi_d"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Forward model in a compact form\n",
            "For convenience we would like to capture the process we just implemented and express the construction of the data vector $\\mathbf{d}$ from a property vector $\\mathbf{m}$ in matrix. \n",
            "\n",
            "Recall that the FEM approximation \n",
            "of the gravity potential $u^{h}$ is the solution of the weak problem   \n",
            "\\begin{equation}\\label{eq:GRAVINV1}\n",
            "\\int_{\\Omega} \\nabla v^{h}  \\cdot \\nabla u^{h}  \\; dx =\n",
            "\\int_{\\Omega} \\rho v^{h}  \\; dx \n",
            "\\end{equation}\n",
            "for all test functions $v^{h}$. For a given data vector $\\mathbf{m}=[m_0,\\ldots,m_{N_p-1}]^T$ \n",
            "the density is taking the form   \n",
            "\\begin{equation}\\label{EQ:DENS2xb}\n",
            "\\rho = \\sum_{k=0}^{N_p-1} m_k \\chi_{k}\n",
            "\\end{equation}\n",
            "as introduced earlier. With this we get\n",
            "\\begin{equation}\\label{eq:GRAVINV2.1}\n",
            "\\int_{\\Omega} \\nabla v^{h}  \\cdot \\nabla u^{h}  \\; dx =\n",
            "\\sum_{i=0}^{N_p-1}  m_k \\int_{\\Omega} \\chi_k v^{h}  \\; dx \n",
            "\\end{equation}\n",
            "for all test functions $v^{h}$. \n",
            "\n",
            "We can grab the values $\\mathbf{U}^{h}$ of the FEM solution $u^{h}$ at the \n",
            "nodes at the FEM (duality of FEM node and basis). We express this in compact form and write\n",
            "\\begin{equation}\n",
            "\\mathbf{U}^{h} =\\mathbf{L}^{h}[\\mathbf{m}] \\;. \n",
            "\\end{equation}\n",
            "So keep in mind that every time you see $\\mathbf{L}^{h}[\\mathbf{m}]$ we solve the FEM problem \\eqref{eq:GRAVINV2.1}; this is the statement `u=model.getSolution()`.\n",
            "\n",
            "Then we calculate vertical gravity $g_z$ at some element centers  $\\mathbf{x}_i$ \n",
            "to obtain the data vector $\\mathbf{d}$ from $\\mathbf{U}^{h}$ or $u^h$. \n",
            "This was done by the statements:\n",
            "\n",
            "    gz=-grad(u, ReducedFunction(domain))[1]\n",
            "    gz_line=np.array(line_locator.getValue(gz))*mGal\n",
            "    d=gz_line[::DataStep].copy()\n",
            "\n",
            "In mathematical terms that means \n",
            "\\begin{equation}\n",
            "d_i=F_i(\\mathbf{m})= g_z(\\mathbf{x}_i) = - \\left.\\frac{\\partial u^h}{\\partial x_1}\\right|_{\\mathbf{x}=\\mathbf{x}_i}\n",
            "\\end{equation}\n",
            "As in the FEM space the gradient calculation uses FEM nodes values (see lectures) \n",
            "\\begin{equation}\\label{eq:forward2}\n",
            "d_i = \\mathbf{B}_i^T \\mathbf{U}^{h}\n",
            "\\end{equation}\n",
            "with a suitable vector $\\mathbf{B}_i$ of length $N$ = number FEM nodes. So keep in mind that every time you see $\\mathbf{B}_i^T \\mathbf{U}$ this means to calculate the gradient of the FEM solution with values $\\mathbf{U}$ and pick its value at point $\\mathbf{x}_i$ as in the three lines of python code shown above.\n",
            "\n",
            "We can put this two steps together to write the \n",
            "calculation of predicted observations $\\mathbf{d}=[d_0, \\ldots, d_{N_d-1}]^T$ in a compact matrix form\n",
            "\\begin{equation}\\label{eq:forward3}\n",
            "\\mathbf{d} = \\mathbf{B} \\mathbf{L}^{h}[\\mathbf{m}] \n",
            "\\end{equation}\n",
            "with $N_d \\times N$ matrix $\\mathbf{B}$ combining the evaluation of the \n",
            "vertical gravity from the FEM solution $\\mathbf{u}^h$ at the observation points."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Critical Point Condition\n",
            "\n",
            "To find the solution of the minimization for $N_p$ real unknowns we use: \n",
            "\n",
            "*A necessary condition for a solution $\\mathbf{m}^{*}$ of the minimization problem \\eqref{eq:minimization}\n",
            "is that $\\mathbf{m}^{*}$ is a critical point of the cost function $\\Phi_d$.*\n",
            "\n",
            "\n",
            "That means\n",
            "that at $\\mathbf{m}^{*}$ all partial derivatives of $\\Phi_d$ take the value zero at the same time:\n",
            "\\begin{equation}\\label{eq:criticalpoint}\n",
            "\\left. \\frac{\\partial \\Phi_d}{\\partial m_k} \\right|_{\\mathbf{m}=\\mathbf{m}^{*}}= 0 \n",
            "\\end{equation}\n",
            "for all $k=0 \\ldots N_p-1$. \n",
            "\n",
            "From the definition of the data misfit function one obtains\n",
            "\\begin{equation}\\label{eq:criticalpoint2}\n",
            "\\frac{\\partial \\Phi_d}{\\partial m_k} \n",
            "= \\sum_{i=0}^{N_d-1} w^{obs}_i \\cdot (F_i(\\mathbf{m})-d_i^{obs}) \n",
            "\\frac{\\partial F_i}{\\partial m_k}\n",
            "\\end{equation}\n",
            "The key terms are $\\frac{\\partial F_i}{\\partial m_k}$\n",
            "which are assembled in so-called Jacobean matrix $\\mathbf{J}=(J_{ik})$:\n",
            "\\begin{equation}\\label{eq:jacobean}\n",
            "J_{ik} = \\frac{\\partial F_i}{\\partial m_k}\n",
            "\\end{equation}\n",
            "$\\mathbf{J}$ is an $N_d \\times N_p$ matrix.\n",
            "\n",
            "In matrix notation the critical point condition \\eqref{eq:criticalpoint} is given as\n",
            "\\begin{equation}\\label{eq:criticalpoint3}\n",
            "\\mathbf{J}^T \\mathbf{W}_d (\\mathbf{F}(\\mathbf{m}^*)-\\mathbf{d}^{obs}) =\\mathbf{0}\n",
            "\\end{equation}\n",
            "$\\mathbf{J}$ is a measure of changes in the data predictions\n",
            "due to changes in physical properties. It is also called sensitivity.\n",
            "\n",
            "Question now is how do we calculate the Jacobean matrix for the gravity problem."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Jacobean for the gravity problem\n",
            "\n",
            "As matrix $\\mathbf{B}_i$ (to grab vertical gravity at an observation point) \n",
            "is not depending on FEM \n",
            "solution $\\mathbf{U}^h =\\mathbf{L}^h[\\mathbf{m}]$ one has\n",
            "\\begin{equation}\\label{eq.FEMgradmatrix} \n",
            "J_{ik} = \\frac{\\partial F_i}{\\partial m_k} = \\mathbf{B}_i \\cdot \\frac{\\partial \\mathbf{U}^h}{\\partial m_k}\n",
            "\\end{equation}\n",
            "with $\\frac{\\partial \\mathbf{U}^h}{\\partial m_k} = \n",
            "\\left[ \\frac{\\partial U^h_0}{\\partial m_k}, \\ldots, \\frac{\\partial U^h_{N-1}}{\\partial m_k} \\right]^T$. From \n",
            "the FEM basis representation \n",
            "\\begin{equation}\\label{eq.FEMinterpol3} \n",
            "u^h = \\sum_{p=0}^{N-1} U^h_p \\phi^h_p\n",
            "\\end{equation}\n",
            "partial derivative of the FEM solution $u^h$ with respect to $m_k$ is given \n",
            "as\n",
            "\\begin{equation}\\label{eq.FEMinterpol3.1} \n",
            "\\frac{\\partial u^h}{\\partial m_k} = \\sum_{p=0}^{N-1} \\frac{\\partial U^h_p}{\\partial m_k} \\phi^h_p\n",
            "\\end{equation}\n",
            "We apply derivation respect of $m_k$ the to  weak from of the PDE \\eqref{eq:GRAVINV1} for $u^h$:\n",
            "\\begin{equation}\\label{eq:GRAV.DERIV1.1}\n",
            "\\int_{\\Omega} \\nabla v^{h}  \\cdot \\nabla \\frac{\\partial u^h}{\\partial m_k}  \\; dx =\n",
            "\\int_{\\Omega} \\frac{\\partial \\rho}{\\partial m_k}  v^{h}  \\; dx \n",
            "\\end{equation}\n",
            "for all $v^h$. \n",
            "\n",
            "From the expression for a piecewise constant density $\\rho$ with coefficients $\\mathbf{m}$ :\n",
            "\\begin{equation*}\n",
            "\\rho = \\sum_{l=0}^{N_p-1} m_l \\chi_{l}\n",
            "\\end{equation*}\n",
            "one gets\n",
            "\\begin{equation}\\label{eq:jacobean2}\n",
            "\\frac{\\partial \\rho}{\\partial m_k} =  \\sum_{l=0}^{N_p-1}  \\delta_{lk} \\chi_l = \\chi_k\n",
            "\\end{equation}\n",
            "which leads to\n",
            "\\begin{equation}\\label{eq:GRAVINV1.1}\n",
            "\\int_{\\Omega} \\nabla v^{h}  \\cdot \\nabla u^{h;k}  \\; dx =\n",
            "\\int_{\\Omega} \\chi_k  v^{h}  \\; dx \n",
            "\\end{equation}\n",
            "with $\\displaystyle{u^{h;k}=\\frac{\\partial u^h}{\\partial m_k}}$. \n",
            "We collect the values of \n",
            "$u^{h;k}$ at the FEM nodes in vector $\\mathbf{K}_k=\\displaystyle{\\frac{\\partial \\mathbf{U}^h}{\\partial m_k}}$ \n",
            "and then can write Jacobean as \n",
            "\\begin{equation}\\label{eq.FEMgradmatrix1} \n",
            "J_{ik} = \\mathbf{B}^T_i \\cdot \\mathbf{K}_k\n",
            "\\end{equation}\n",
            "for $i=0,\\ldots, N_d$ and $k=0,\\ldots N_p$. \n",
            "\n",
            "We can easily implement this:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "J=np.zeros((d_obs.size, len(chis)))\n",
            "for k in range(len(chis)):\n",
            "    model.setValue(Y=-4*np.pi*G*chis[k])\n",
            "    uk=model.getSolution() # = K_k\n",
            "    gzk=-grad(uk, ReducedFunction(domain))[1]\n",
            "    gzk_line=np.array(line_locator.getValue(gzk))*mGal \n",
            "    J[:,k]=gzk_line[::DataStep] # = B.K_k"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "for k in [0, 10, 20]:\n",
            "    plt.plot(x0_line[::DataStep], J[:,k], label=f'col {k}')\n",
            "plt.xlabel('x [m]')\n",
            "plt.ylabel('gravity [mGal]')\n",
            "plt.legend()\n",
            "plt.title(\"Columns of the Jacobean\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### The linear model case \n",
            "The entries of matrix $\\mathbf{K}_k$ are independent from $\\mathbf{m}$ which also means that the forward problems $F_i$ are changing linear with the physical property vector. As a consequence we can use $\\mathbf{K}_k$ also to calculate the FEM solution $u^h$ for a given property $\\mathbf{m}$. \n",
            "The density $\\rho$ is variational equation \\eqref{eq:GRAVINV1} is written as \n",
            "\\begin{equation}\\label{eq:GRAVINV2}\n",
            "\\int_{\\Omega} \\rho v^{h}  \\; dx = \\sum_{k=0}^{N_p-1}  m_k \\int_{\\Omega} \\chi_k v^{h}  \\; dx \n",
            "= \\sum_{k=0}^{N_p-1} m_k  \\int_{\\Omega} \\nabla v^{h}  u^{h;k}  \\; dx = \n",
            "\\int_{\\Omega} \\nabla v^{h} \\cdot \\nabla  \\left(\\sum_{k=0}^{N_p-1} m_k u^{h;k} \\right) \\; dx\n",
            "\\end{equation}\n",
            "for all test functions $v^{h}$. This shows that in fact \n",
            "\\begin{equation}\\label{eq:GRAFIT5}\n",
            "u^{h}  = \\sum_{i=0}^{N_p-1} m_k u^{h;k}\n",
            "\\end{equation}\n",
            "is the FEM potential for a given  property vector $\\mathbf{m}=[m_k]$.\n",
            "This translates to nodal values in the form\n",
            "\\begin{equation}\\label{eq:GRAFIT6}\n",
            "\\mathbf{U}^{h}  = \\sum_{i=0}^{N_p-1} m_k \\mathbf{K}_k\n",
            "\\end{equation}\n",
            "and for the data vector $\\mathbf{d}=[d_i]$\n",
            "\\begin{equation}\\label{eq:GRAFIT8}\n",
            "d_i = \\mathbf{B}_i^T \\mathbf{U}^{h} = \\sum_{k=0}^{N_p-1} m_k \\mathbf{B}_i^T \\mathbf{K}_k \n",
            " = \\sum_{k=0}^{N_p-1} J_{ik} m_k \n",
            "\\end{equation}\n",
            "or \n",
            "\\begin{equation}\\label{eq:GRAFIT8.1}\n",
            "\\mathbf{d} = \\mathbf{J} \\mathbf{m}\n",
            "\\end{equation}\n",
            "Notice that in general such identity applies only when the forward model is linear function of the\n",
            "physical parameters such as the gravity and the magnetic but this will not apply for instance in the MT case.\n",
            "\n",
            "With all this work we can restate the critical point condition \\eqref{eq:criticalpoint2} can be written\n",
            "\\begin{equation}\\label{eq:criticalpoint2.2}\n",
            "(\\mathbf{J}^T \\mathbf{W}_d \\mathbf{J}) \\mathbf{m} = \\mathbf{J}^T \\mathbf{W}_d \\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "This is a system of $N_p$  linear equations for the unknown property vector $\\mathbf{m}$ with \n",
            "$N_p$ component. In the literature the equation is often referred as the normal equation of \n",
            "\\begin{equation}\\label{eq:criticalpoint2.3}\n",
            "\\mathbf{W}_d^{\\frac{1}{2}} \\mathbf{J} \\mathbf{m} = \\mathbf{W}_d^{\\frac{1}{2}} \\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "To make live a bit easier we assume that all measurement errors $\\sigma_i$ are the same \n",
            "and hence the matrix $\\mathbf{W}_d$ is the identity matrix.\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Solution\n",
            "\n",
            "### First Attempt\n",
            "\n",
            "There are a variety of solvers approaches available to solve these type of equations \n",
            "as provided by the python function `scipy.linalg.lstsq` in python, see [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html).\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from scipy.linalg import lstsq\n",
            "m_scipy, res, rnk, s=lstsq(J, d_obs)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "And plot the result:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.clf()\n",
            "vmax=abs(m_scipy).max()\n",
            "plt.imshow(m_scipy.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Ops!** Values far to large! Wrong location of anomalies!"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m_scipy"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho_scipy=0\n",
            "for k in range(len(m_scipy)):\n",
            "    rho_scipy=rho_scipy+chis[k]*m_scipy.flat[k]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.setValue(Y=-4*np.pi*G*rho_scipy)\n",
            "u_scipy=model.getSolution()\n",
            "gz_scipy=-grad(u_scipy, ReducedFunction(domain))[1]*mGal\n",
            "d_scipy=np.array(line_locator.getValue(gz_scipy))[::DataStep].copy()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "#plt.plot(x0_line,line_locator.getValue(gz_drop), label='gz')\n",
            "plt.scatter(x0_line[::DataStep], d_obs, s=5, label='data')\n",
            "plt.scatter(x0_line[::DataStep], d_scipy, s=5, label='recovered')\n",
            "\n",
            "plt.xlabel('x [m]')\n",
            "plt.ylabel('gravity [mGal]')\n",
            "plt.legend()\n",
            "plt.title(\"gravity anomaly over transect @ height %g m\"%(line_locator.getX()[0][1]))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### SVD\n",
            "To get a better understanding of what is going on we apply a singular value decomposition (SVD)\n",
            "to the Jacobean $\\mathbf{J}$.\n",
            "\n",
            "What exactly is this an SVD? \n",
            "\n",
            "We try the respective function `numpy.linalg.svd` of `numpy`. It returns three arrays:\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "U, s, V = np.linalg.svd(J, full_matrices=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Lets check shapes:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "U.shape, s.shape, V.shape, J.shape"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Idea is that matrix `U` is an orthogonal matrix, that is $\\mathbf{U}^T \\mathbf{U} = \\mathbf{I}$. \n",
            "Is this true?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.allclose(np.eye(24), U.T @ U)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The same is true for `V` - also an orthogonal matrix. Really?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.allclose(np.eye(24), V.T @ V)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The idea is that the matrices $\\mathbf{U}$ and $\\mathbf{V}$ transfer $\\mathbf{J}$ into a diagonal matrix with\n",
            "main diagonal given by array `s`. This is \n",
            "\\begin{equation}\\label{eq:SVD1}\n",
            "\\mathbf{U}^T \\mathbf{J} \\mathbf{V}^T = \\mathbf{S} =\n",
            "\\begin{bmatrix}\n",
            "s_0  & 0        &            & 0\\\\\n",
            "    0      &  s_1&           & 0\\\\\n",
            "    \\vdots       &        & \\ddots &    \\vdots\\\\\n",
            "        0         &       &       & s_{N_p-1}\n",
            "\\end{bmatrix}\n",
            "\\end{equation}\n",
            "The values $s_0, \\ldots, s_{N_p-1}$ are called the singular values of $\\mathbf(J}$. Thry are always real and non-negative.\n",
            "\n",
            "Is this working?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.allclose( np.diag(s), U.T @ J @ V.T)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Why is this useful? We can apply this to the critical point condition \\eqref{eq:criticalpoint2.2}:  \n",
            "\\begin{equation}\\label{eq:criticalpoint2.V2}\n",
            "(\\mathbf{J}^T \\mathbf{J}) \\mathbf{m} = \\mathbf{J}^T \\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "in the form\n",
            "$$\n",
            "\\mathbf{U} \\mathbf{S} \\mathbf{V}= \\mathbf{J}\n",
            "$$\n",
            "This gives\n",
            "\\begin{equation}\\label{eq:criticalpoint2.V3}\n",
            "(\\mathbf{V}^T \\mathbf{S} \\mathbf{U}^T \\mathbf{U} \\mathbf{S} \\mathbf{V}) \\mathbf{m} = \\mathbf{V}^T \\mathbf{S} \\mathbf{U}^T\\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "We multiply by $ \\mathbf{S}^{-1} \\mathbf{V}$ and obtain\n",
            "\\begin{equation}\\label{eq:criticalpoint2.V4}\n",
            " \\mathbf{S} \\mathbf{V} \\mathbf{m} = \\mathbf{U}^T\\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "which gives solution\n",
            "\\begin{equation}\\label{eq:criticalpoint2.V5}\n",
            "\\mathbf{m} =  \\mathbf{V}^T \\mathbf{S}^{-1} \\mathbf{U}^T\\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "Is this really the same solution as we got from `scipy.linalg.lstsq`?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.allclose(m_scipy, np.dot((V.T*1/s) @ U.T, d_obs), atol=0.)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Some Analysis\n",
            "\n",
            "We set $\\hat{\\mathbf{d}}=\\mathbf{U}^T\\mathbf{d}^{obs}$ which is is essence is just a change of variables in the space of the observations. With the rows $\\mathbf{v}_0, \\ldots, \\mathbf{v}_{N_p-1}$ of matrix $\\mathbf{V}$ (also called modes)\n",
            "we then write the solution $\\mathbf{m}$ in the following form: \n",
            "\\begin{equation}\\label{eq:svn4PASS}\n",
            "\\mathbf{m} =  \\sum_{k=0}^{N_p-1} \\frac{\\hat{d}_k}{s_k} \\mathbf{v}_k\n",
            "\\end{equation}\n",
            "We see that the solution is a linear combinations of the rows of $\\mathbf{V}$ where \n",
            "rows that belong to small singular values make the largest contributions - if the respective data contribution $\\hat{d}_k$ is not zero as we can assume for data with noise.\n",
            "\n",
            "Let's check the singular values (they are always returned in the order increasing value): "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "s[0]/s[-1]*1e-11, s[1], s[-1]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We see that the smalles singular value $ \\approx 10^{-13}$ is extremely small compared to the largerest $10^{-1}$ which means that the solution is dominated by $\\bathbf{v}_{23}$.\n",
            "\n",
            "How does this look like?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m=V[-1,:]\n",
            "plt.clf()\n",
            "vmax=abs(m).max()\n",
            "plt.imshow(m.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for s={s[-1]}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m=V[-2,:]\n",
            "plt.clf()\n",
            "vmax=abs(m).max()\n",
            "plt.imshow(m.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for s={s[-2]}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "These look very similar to what the solver returned. \n",
            "\n",
            "Let's test some of the other modes:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m=V[2,:]\n",
            "plt.clf()\n",
            "vmax=abs(m).max()\n",
            "plt.imshow(m.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for s={s[2]}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m=V[10,:]\n",
            "plt.clf()\n",
            "vmax=abs(m).max()\n",
            "plt.imshow(m.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for s={s[1]}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The vector $\\mathbf{V} \\mathbf{m}_{true}$ shows us which modes give  the largest contribution to the true solution:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.dot(V, m_true.flat)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Largest contribution from s[13]:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m=V[13,:]\n",
            "plt.clf()\n",
            "vmax=abs(m).max()\n",
            "plt.imshow(m.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for s={s[13]}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "What did we learn?\n",
            "\n",
            "- The large ratio of largest to smallest singular value leads to over emphasising modes corresponding to the smallest singular values. This characteristic is called ill-posedness. \n",
            "- In ill-post problems noise in the input can result in solutions that are far off from the true solution.\n",
            "- inversion is an ill-posed problem.\n",
            "\n",
            "So what can we do about this?"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Solution Strategies\n",
            "\n",
            "There are  a few thing one can try to address this issue. \n",
            "It always comes at some costs in terms of the accuracy of the returned solution.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Mode dropping\n",
            "\n",
            "If a SVD of the Jacobean $\\mathbf{J}$ is available a simple strategy is to suppress contributions from the \n",
            "low singular values. This approach is motivated by the idea that these \n",
            "small singular values should (maybe) actually be considered as zeros.\n",
            "This concept of a high-pass filter is formally introduced by introducing\n",
            "weighting factors factors $\\varrho_k$ into \n",
            "the calculation of the solution $\\mathbf{m}$ in \\eqref{eq:svn4PASS}\n",
            " \\begin{equation}\\label{eq:svn4PASS DROP}\n",
            "\\mathbf{m} = \\sum_{i=0}^{N_p-1} \\varrho_k \\cdot \\frac{\\hat{d}_k}{s_{k}} \\mathbf{v}_k\n",
            "\\end{equation}\n",
            "the idea being that $\\varrho_k$ takes small values or set to zero \n",
            "for those singular values $s_k$ that are supposed to be suppressed. \n",
            "The simplest approach is simply switch off \n",
            "the *nasty* terms in \\eqref{eq:svn4PASS} that is to \n",
            "ignore all terms for singular values less than\n",
            "given threshold $\\tau$ that means\n",
            "we set  \n",
            "\\begin{equation}\\label{eq:filter}\n",
            "\\varrho_k =\n",
            " \\left\\{ \n",
            "\\begin{array}{cl}\n",
            "1 & s_k > \\tau  \\\\\n",
            "0 & \\mbox{ otherwise }\n",
            "\\end{array}\n",
            "\\right.\n",
            "\\end{equation}\n",
            "This acts as a discriminating high-pass filter.\n",
            "It introduces a deviation from the original \n",
            "problem \\eqref{eq:criticalpoint2.2} to be solved but dumps the components that introduce ill-posedness.\n",
            "The larger value for the cut off  $\\tau$ is chosen \n",
            "the better the problem becomes conditioned but at the same time the\n",
            "larger the deviation from the original problem get. So a value needs to be chosen that provides a balance between these two conflicting targets. Typically one chooses \n",
            "$$\n",
            "\\tau = \\alpha \\cdot \\underset{k}{max} \\; s_k\n",
            "$$\n",
            "with for instance $\\alpha = 0.001$.\n",
            "\n",
            "We put this to the test:"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "First find the index `drop` at which the "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "alpha=5e-3\n",
            "drop=np.argmax(s<alpha*max(s)) # returns index of first True\n",
            "drop"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "d_hat=np.dot(U.T, d_obs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m_drop=np.dot(V.T[:,:drop], d_hat[:drop]/s[:drop])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.clf()\n",
            "vmax=abs(m_drop).max()\n",
            "plt.imshow(m_drop.reshape(PatchGrid_coarse).T, origin='lower',  vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for with drop tolerance alpha={alpha}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "What about the misfit?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho_drop=0\n",
            "for k in range(len(m_drop)):\n",
            "    rho_drop=rho_drop+chis[k]*m_drop.flat[k]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.setValue(Y=-4*np.pi*G*rho_drop)\n",
            "u_drop=model.getSolution()\n",
            "gz_drop=-grad(u_drop, ReducedFunction(domain))[1]*mGal\n",
            "d_drop=np.array(line_locator.getValue(gz_drop))[::DataStep].copy()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sqrt(np.mean((d_drop-d_obs)**2)) ,sqrt(np.mean((d_obs)**2))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "#plt.plot(x0_line,line_locator.getValue(gz_drop), label='gz')\n",
            "plt.scatter(x0_line[::DataStep], d_obs, s=5, label='data')\n",
            "plt.scatter(x0_line[::DataStep], d_drop, s=5, label='recoverd')\n",
            "\n",
            "plt.xlabel('x [m]')\n",
            "plt.ylabel('gravity [mGal]')\n",
            "plt.legend()\n",
            "plt.title(\"gravity anomaly over transect @ height %g m\"%(line_locator.getX()[0][1]))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Filtering\n",
            "\n",
            "A discriminating approach for a high-pass filter may be a bit harsh\n",
            "as modes can only be switched on or off and so changes to the cut off could lead to significant changes in the result. A more appropriate strategy could be a continuous transition between zero to switch of \n",
            "small singular values and one to keep contributions from modes for large singular values. For instance one can set \n",
            " \\begin{equation}\\label{eq:svn4.1}\n",
            "\\varrho_k = \\frac{ s_k^2}{s_k^2+\\tau^2}\n",
            "\\end{equation}\n",
            "This looks like\n",
            "<img src=\"./Data/IMAGE_filter_function.png\" width=\"400\">\n",
            "(soft) cut-offs $\\tau$. Notice the log scale on the $s$ axis.\n",
            "This selection is weighting factors is referred to as Wiener weights.\n",
            "Singular values lower than $\\tau$ receive a\n",
            "weighting $\\varrho$ less than $\\frac{1}{2}$. Obviously \n",
            "there are other options to introduce a smooth \n",
            "high-pass filter.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tau=1.e-2*max(s)\n",
            "m_f=np.dot(V.T, d_hat/s * s**2/(s**2+tau**2))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Would be interesting to see the contribution of modes:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "plt.plot(s, s/(s**2+tau**2), label=\"filtered\")\n",
            "plt.plot(s, 1/s, label=\"original\")\n",
            "plt.xlabel(\"s\")\n",
            "plt.ylabel(\"filtered\")\n",
            "plt.xscale('log')\n",
            "plt.yscale('log')\n",
            "plt.legend()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.clf()\n",
            "vmax=abs(m_f).max()\n",
            "plt.imshow(m_f.reshape(PatchGrid_coarse).T, origin='lower', vmin=-vmax, vmax=vmax, cmap='seismic')\n",
            "plt.colorbar()\n",
            "plt.title(f\"mode for Wiener filter tau={tau:.2g}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "rho_f=0\n",
            "for k in range(len(m_f)):\n",
            "    rho_f=rho_f+chis[k]*m_f.flat[k]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.setValue(Y=-4*np.pi*G*rho_f)\n",
            "u_f=model.getSolution()\n",
            "gz_f=-grad(u_f, ReducedFunction(domain))[1]*mGal\n",
            "d_f=np.array(line_locator.getValue(gz_f))[::DataStep].copy()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sqrt(np.mean((d_f-d_obs)**2)), sqrt(np.mean((d_obs)**2))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "#plt.plot(x0_line,line_locator.getValue(gz_drop), label='gz')\n",
            "plt.scatter(x0_line[::DataStep], d_obs, s=8, label='data')\n",
            "plt.scatter(x0_line[::DataStep], d_f, s=5, label='recoverd')\n",
            "\n",
            "plt.xlabel('x [m]')\n",
            "plt.ylabel('gravity [mGal]')\n",
            "plt.legend()\n",
            "plt.title(\"gravity anomaly over transect @ height %g m\"%(line_locator.getX()[0][1]))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Regularization\n",
            "\n",
            "Another approach is going back to the inversion problem and modify the objective function to be minimized. The idea is to bound the values property function $\\mathbf{m}$ and add a penalty term to the misfit. So instead \n",
            "of minimizinf $\\Phi_d$ we now minimize now\n",
            "$$\n",
            "\\Phi(\\mathbf{m}) =  \\Phi_d(\\mathbf{m}) + \\mu \\frac{1}{2}  \\mathbf{m}^T\\mathbf{m}\n",
            "$$\n",
            "for some positive penalty factor $\\mu$. This approach is called regularization and \n",
            "the extra term is called the regularization term. This approach is attractive as we do not need \n",
            "a SVD of $\\mathbf{J}$. \n",
            "\n",
            "Again the solution $\\mathbf{m}$ is given as a critical point which \n",
            "means that all partial derivatives of $\\Phi$ withe respect to $m_k$ take the value zero at the same time:\n",
            "\\begin{equation}\\label{eq:criticalpoint R}\n",
            "\\left. \\frac{\\partial \\Phi}{\\partial m_k} \\right|_{\\mathbf{m}=\\mathbf{m}^{*}}= 0 \n",
            "\\end{equation}\n",
            "for all $k=0 \\ldots N_p-1$. This leads to the condition \n",
            "\\begin{equation}\\label{eq:criticalpoint2R}\n",
            "\\frac{\\partial \\Phi}{\\partial m_k} \n",
            "= \\mu \\cdot m_k +\\sum_{i=0}^{N_d-1} (F_i(\\mathbf{m})-d_i^{obs})  =\n",
            "\\frac{\\partial F_i}{\\partial m_k}\n",
            "\\end{equation}\n",
            "Bringing in the Jacobean matrix $\\mathbf{J}=(J_{ik})$\n",
            "\\begin{equation}\\label{eq:criticalpoint3R}\n",
            "\\mu \\mathbf{m}^* + \\mathbf{J}^T (\\mathbf{J}\\mathbf{m}^*-\\mathbf{d}^{obs}) =\\mathbf{0}\n",
            "\\end{equation}\n",
            "which we can write in the form (dropping the upper index $*$)\n",
            "\\begin{equation}\\label{eq:criticalpoint3RS}\n",
            "( \\mu \\mathbf{I} + \\mathbf{J}^T \\mathbf{J}) \\mathbf{m} = \\mathbf{J}^T \\mathbf{d}^{obs}\n",
            "\\end{equation}\n",
            "This can easily be solved by inverting the matrix $\\mu \\mathbf{I} + \\mathbf{J}^T \\mathbf{J}$.\n",
            "For $\\mu=0$ we are back to the original ill-posed problem. Did we really gain anything?\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "From the SVD compostion we have:\n",
            "$$\n",
            "\\mu \\mathbf{I} + \\mathbf{J}^T \\mathbf{J} = \n",
            "\\mathbf{V}^T(\\mu \\mathbf{I} +  \\mathbf{S}^2) \\mathbf{V}\n",
            "$$\n",
            "as $\\mathbf{V}$ is orthogonal. Hence we have \n",
            "$$\n",
            "(\\mu \\mathbf{I} + \\mathbf{J}^T \\mathbf{J})^{-1} = \n",
            "\\mathbf{V}^T(\\mu \\mathbf{I} + \\mathbf{S}^2)^{-1} \\mathbf{V}\n",
            "=\\mathbf{V}^T \\mathbf{D}^{-1}\\mathbf{V}\n",
            "$$\n",
            "with diagonal matrix\n",
            "$$\n",
            "\\mathbf{D} =\n",
            "\\begin{bmatrix}\n",
            "\\mu+s_0^2  & 0        &            & 0\\\\\n",
            "    0      &  \\mu+s_1^2&           & 0\\\\\n",
            "    \\vdots       &        & \\ddots &    \\vdots\\\\\n",
            "        0         &       &       & \\mu+s_{N_p-1}^2\n",
            "\\end{bmatrix}\n",
            "$$\n",
            "And right hand side is then\n",
            "$$\n",
            "\\mathbf{J}^T \\mathbf{d}^{obs}=\\mathbf{V}^T \\mathbf{S}  \\mathbf{U}^T \\mathbf{d}^{obs} = \n",
            "\\mathbf{V}^T \\mathbf{S} \\hat{\\mathbf{d}}^{obs}\n",
            "$$\n",
            "So the solution $\\mathbf{m}$ is given as\n",
            "$$\n",
            "\\mathbf{m} = \\mathbf{V}^T \\mathbf{D}^{-1} \\mathbf{S}\\hat{\\mathbf{d}}^{obs} \n",
            "$$\n",
            "What is $\\mathbf{D}^{-1} \\mathbf{S}$?\n",
            "$$\n",
            "\\mathbf{D}^{-1} \\mathbf{S} =\n",
            "\\begin{bmatrix}\n",
            "\\frac{s_0}{\\mu+s_0^2}  & 0        &            & 0\\\\\n",
            "    0      &  \\frac{s_1}{\\mu+s_1^2}&           & 0\\\\\n",
            "    \\vdots       &        & \\ddots &    \\vdots\\\\\n",
            "        0         &       &       & \\frac{s_0}{\\mu+s_{N_p-1}^2}\n",
            "\\end{bmatrix}\n",
            "$$\n",
            "Do you recognize this?"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This is the same as the Wiener filter:\n",
            "$$\n",
            "[\\mathbf{D}^{\u22121}\\mathbf{S}]_{kk}=\\frac{s_0}{\\mu+s_0^2} =\\frac{\\varrho_k}{s_k}\n",
            "$$\n",
            "if we set $\\mu=\\tau^2$."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's put is to the test:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "mu=tau**2"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Get the solution $\\matbf{m}_r$ from solving with regularization\n",
            "$$\n",
            "\\mathbf{m}_r=( \\mu \\mathbf{I} + \\mathbf{J}^T \\mathbf{J})^{-1} \\mathbf{J}^T \\mathbf{d}^{obs}\n",
            "$$\n",
            "and then compare with the solution $\\mtahbf{m}_f$ with Weiner filtering:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "m_r=np.linalg.solve(mu*np.eye(s.size)+J.T @ J, np.dot(J.T, d_obs))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.allclose(m_f, m_r)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Excellent we don't need the SVD but value $\\mu$ becomes guesswork then."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## L-curves\n",
            "\n",
            "A way to identify a good regularization parameter is plotting the values of the misfit $\\Phi_p$ versus the regularization term (without the $\\mu$ factor). One is looking for the point when further increase of the $\\mu$ enforcing a more regular $\\mathbf{m}$ starts to make a significant impact on an increase of the mi"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "fit=[]\n",
            "reg=[]\n",
            "qs=[]\n",
            "for q in np.linspace(-7,0,50):\n",
            "    mu=10**q\n",
            "    m_r=np.linalg.solve(mu*np.eye(s.size)+J.T @ J, np.dot(J.T, d_obs))\n",
            "    rho_r=0\n",
            "    for k in range(len(m_r)):\n",
            "        rho_r=rho_r+chis[k]*m_r[k]\n",
            "    model.setValue(Y=-4*np.pi*G*rho_r)\n",
            "    u_r=model.getSolution()\n",
            "    gz_r=-grad(u_r, ReducedFunction(domain))[1]*mGal\n",
            "    d_r=np.array(line_locator.getValue(gz_r))[::DataStep].copy()\n",
            "    fit.append(np.mean((d_r-d_obs)**2))\n",
            "    reg.append(np.dot(m_r,m_r)/1000.)\n",
            "    qs.append(q)\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "plt.figure()\n",
            "plt.plot(reg, fit)\n",
            "plt.scatter(np.dot(m_f,m_f)/1000,np.mean((d_f-d_obs)**2))\n",
            "for i, q in enumerate(qs):\n",
            "    plt.annotate(f\"{q:.1f}\", (reg[i], fit[i]))\n",
            "plt.xlabel(\"regularization\")\n",
            "plt.ylabel(\"misfit\")\n",
            "#plt.yscale(\"log\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "celltoolbar": "Tags",
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.6"
      },
      "latex_envs": {
         "LaTeX_envs_menu_present": true,
         "autoclose": false,
         "autocomplete": false,
         "bibliofile": "biblio.bib",
         "cite_by": "apalike",
         "current_citInitial": 1,
         "eqLabelWithNumbers": true,
         "eqNumInitial": 1,
         "hotkeys": {
            "equation": "Ctrl-E",
            "itemize": "Ctrl-I"
         },
         "labels_anchors": false,
         "latex_user_defs": false,
         "report_style_numbering": false,
         "user_envs_cfg": false
      },
      "toc": {
         "base_numbering": 1,
         "nav_menu": {},
         "number_sections": true,
         "sideBar": false,
         "skip_h1_title": false,
         "title_cell": "Table of Contents",
         "title_sidebar": "Contents",
         "toc_cell": true,
         "toc_position": {},
         "toc_section_display": false,
         "toc_window_display": false
      },
      "varInspector": {
         "cols": {
            "lenName": 16,
            "lenType": 16,
            "lenVar": 40
         },
         "kernels_config": {
            "python": {
               "delete_cmd_postfix": "",
               "delete_cmd_prefix": "del ",
               "library": "var_list.py",
               "varRefreshCmd": "print(var_dic_list())"
            },
            "r": {
               "delete_cmd_postfix": ") ",
               "delete_cmd_prefix": "rm(",
               "library": "var_list.r",
               "varRefreshCmd": "cat(var_dic_list()) "
            }
         },
         "position": {
            "height": "752.85px",
            "left": "1550px",
            "right": "20px",
            "top": "120px",
            "width": "350px"
         },
         "types_to_exclude": [
            "module",
            "function",
            "builtin_function_or_method",
            "instance",
            "_Feature"
         ],
         "window_display": false
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}